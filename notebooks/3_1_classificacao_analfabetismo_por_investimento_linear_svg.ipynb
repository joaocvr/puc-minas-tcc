{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Classificação e previsão \n",
    "## 3.1) Quão maior os gastos e investimentos com a educação, menor será a taxa de analfabetismo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1) Carga e transformação da massa bruta de todos os indicadores e países."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "massa_bruta_pais_por_indicadores = pd.read_csv('../data/massa_bruta_pais_por_indicadores.csv')\n",
    "\n",
    "anos = ['1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', \n",
    "        '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013']\n",
    "\n",
    "indicadores = ['UIS.LP.AG15T24', 'UIS.ILLPOP.AG25T64', 'UIS.LP.AG65',\n",
    "               'UIS.XSPENDP.FDPUB.FNS', 'UIS.XSPENDP.FDPUB.FNCAP', 'UIS.XSPENDP.FDPUB.FNNONS', \n",
    "               'UIS.XGDP.FSGOV.FDINSTADM.FFD', 'SE.XPD.TOTL.GD.ZS']\n",
    "\n",
    "paises = massa_bruta_pais_por_indicadores['Country Name'].unique()\n",
    "\n",
    "df_massa_bruta_por_indicador = massa_bruta_pais_por_indicadores.loc[massa_bruta_pais_por_indicadores['Indicator Code'].isin(indicadores)]\n",
    "\n",
    "colunas_transformacao = ['Pais', 'Indicador', '1998-1999', '1999-2000', '2000-2001', '2001-2002', \n",
    "                        '2002-2003', '2003-2004', '2004-2005', '2005-2006', '2006-2007', '2007-2008', \n",
    "                        '2008-2009', '2009-2010', '2010-2011', '2011-2012']\n",
    "df_resultado_transformacao = pd.DataFrame(columns=colunas_transformacao)\n",
    "\n",
    "colunas_transformacao_teste = ['Pais', 'Indicador', '2012-2013']\n",
    "df_resultado_transformacao_teste = pd.DataFrame(columns=colunas_transformacao_teste)\n",
    "\n",
    "for pais in paises:\n",
    "    df_pais = df_massa_bruta_por_indicador.loc[df_massa_bruta_por_indicador['Country Name'] == pais]\n",
    "\n",
    "    df_1998_a_2013 = df_pais.iloc[:, 2:18]\n",
    "    df_1998_a_2013.index = range(df_1998_a_2013.shape[0])\n",
    "    df_1998_a_2013 = df_1998_a_2013.fillna(0)\n",
    "   \n",
    "    indicador = df_pais['Indicator Code']\n",
    "    indicador.index = range(indicador.shape[0])\n",
    "    \n",
    "    for index, indicador in indicador.items():\n",
    "        valor_1998_1999 = 1 if df_1998_a_2013['1999'].iloc[index] - df_1998_a_2013['1998'].iloc[index] > 0 else 0\n",
    "        valor_1999_2000 = 1 if df_1998_a_2013['2000'].iloc[index] - df_1998_a_2013['1999'].iloc[index] > 0 else 0\n",
    "        valor_2000_2001 = 1 if df_1998_a_2013['2001'].iloc[index] - df_1998_a_2013['2000'].iloc[index] > 0 else 0\n",
    "        valor_2001_2002 = 1 if df_1998_a_2013['2002'].iloc[index] - df_1998_a_2013['2001'].iloc[index] > 0 else 0\n",
    "        valor_2002_2003 = 1 if df_1998_a_2013['2003'].iloc[index] - df_1998_a_2013['2002'].iloc[index] > 0 else 0\n",
    "        valor_2003_2004 = 1 if df_1998_a_2013['2004'].iloc[index] - df_1998_a_2013['2003'].iloc[index] > 0 else 0\n",
    "        valor_2004_2005 = 1 if df_1998_a_2013['2005'].iloc[index] - df_1998_a_2013['2004'].iloc[index] > 0 else 0\n",
    "        valor_2005_2006 = 1 if df_1998_a_2013['2006'].iloc[index] - df_1998_a_2013['2005'].iloc[index] > 0 else 0\n",
    "        valor_2006_2007 = 1 if df_1998_a_2013['2007'].iloc[index] - df_1998_a_2013['2006'].iloc[index] > 0 else 0\n",
    "        valor_2007_2008 = 1 if df_1998_a_2013['2008'].iloc[index] - df_1998_a_2013['2007'].iloc[index] > 0 else 0\n",
    "        valor_2008_2009 = 1 if df_1998_a_2013['2009'].iloc[index] - df_1998_a_2013['2008'].iloc[index] > 0 else 0\n",
    "        valor_2009_2010 = 1 if df_1998_a_2013['2010'].iloc[index] - df_1998_a_2013['2009'].iloc[index] > 0 else 0\n",
    "        valor_2010_2011 = 1 if df_1998_a_2013['2011'].iloc[index] - df_1998_a_2013['2010'].iloc[index] > 0 else 0\n",
    "        valor_2011_2012 = 1 if df_1998_a_2013['2012'].iloc[index] - df_1998_a_2013['2011'].iloc[index] > 0 else 0\n",
    "        valor_2012_2013 = 1 if df_1998_a_2013['2013'].iloc[index] - df_1998_a_2013['2012'].iloc[index] > 0 else 0\n",
    "\n",
    "        valores = [pais, indicador, valor_1998_1999, valor_1999_2000, valor_2000_2001, valor_2001_2002, \n",
    "                   valor_2002_2003, valor_2003_2004, valor_2004_2005, valor_2005_2006, valor_2006_2007, \n",
    "                   valor_2007_2008, valor_2008_2009, valor_2009_2010, valor_2010_2011, valor_2011_2012]\n",
    "        \n",
    "        df_auxiliar = pd.DataFrame([valores], columns=colunas_transformacao)\n",
    "        df_auxiliar.index = range(df_auxiliar.shape[0])\n",
    "        df_resultado_transformacao = pd.concat([df_auxiliar, df_resultado_transformacao])\n",
    "        \n",
    "        valores_teste = [pais, indicador, valor_2012_2013]\n",
    "        df_auxiliar_teste = pd.DataFrame([valores_teste], columns=colunas_transformacao_teste)\n",
    "        df_auxiliar_teste.index = range(df_auxiliar_teste.shape[0])\n",
    "        df_resultado_transformacao_teste = pd.concat([df_auxiliar_teste, df_resultado_transformacao_teste])\n",
    "\n",
    "\n",
    "df_resultado_transformacao = df_resultado_transformacao.sort_values(['Pais'], ascending=[True])\n",
    "df_resultado_transformacao.index = range(df_resultado_transformacao.shape[0])\n",
    "\n",
    "df_resultado_transformacao_teste = df_resultado_transformacao_teste.sort_values(['Pais'], ascending=[True])\n",
    "df_resultado_transformacao_teste.index = range(df_resultado_transformacao_teste.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2) Transformação e seleção para o indicador de analfabetismo entre 15 a 24 anos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realiza a listagem dos países que possuem pelo menos 50% dos valores preenchidos para o indicador de analfabetismo de 15 a 24 anos ('UIS.LP.AG15T24')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises_na_media = []\n",
    "df_indicador_15_a_24 = df_massa_bruta_por_indicador.loc[df_massa_bruta_por_indicador['Indicator Code'] == 'UIS.LP.AG15T24']\n",
    "df_indicador_15_a_24.index = range(df_indicador_15_a_24.shape[0])\n",
    "for index, row in df_indicador_15_a_24.iterrows():\n",
    "    pais = row['Country Name']\n",
    "#     media_zeros = row[2:18].isna().mean()\n",
    "#     if media_zeros <= 0.5:\n",
    "#         paises_na_media.append(pais)\n",
    "    paises_na_media.append(pais)\n",
    "\n",
    "df_paises_na_media = pd.DataFrame(columns=['Pais'], data=paises_na_media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforma os indicadores, dos países selecionados acima, em colunas.  Isso é feito para o período entre 1998 e 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicadores_15_a_24 = ['UIS.LP.AG15T24', 'UIS.XSPENDP.FDPUB.FNS', 'UIS.XSPENDP.FDPUB.FNCAP', \n",
    "                       'UIS.XSPENDP.FDPUB.FNNONS', 'UIS.XGDP.FSGOV.FDINSTADM.FFD', 'SE.XPD.TOTL.GD.ZS']\n",
    "\n",
    "df_analfabetismo_15_a_24 = pd.DataFrame()\n",
    "\n",
    "for indicador in indicadores_15_a_24:\n",
    "    df_indicador = df_resultado_transformacao.loc[df_resultado_transformacao['Indicador'] == indicador]\n",
    "    df_indicador = df_indicador.loc[df_indicador['Pais'].isin(df_paises_na_media['Pais'])]\n",
    "    df_indicador.index = range(df_indicador.shape[0])\n",
    "    df_periodos_indicador = df_indicador.drop(['Pais', 'Indicador'], axis=1)    \n",
    "    df_periodos_indicador = df_periodos_indicador.stack()\n",
    "    df_periodos_indicador.index = range(df_periodos_indicador.shape[0])\n",
    "    df_analfabetismo_15_a_24[indicador] = df_periodos_indicador.tolist()\n",
    "\n",
    "nomes_colunas = {'UIS.LP.AG15T24': 'Analfabetismo 15 a 24', \n",
    "                 'UIS.ILLPOP.AG25T64': 'Analfabetismo 25 a 64', \n",
    "                 'UIS.LP.AG65': 'Analfabetismo 65+', \n",
    "                 'UIS.XSPENDP.FDPUB.FNS': 'Gastos Pessoas',\n",
    "                 'UIS.XSPENDP.FDPUB.FNCAP': 'Gastos Totais', \n",
    "                 'UIS.XSPENDP.FDPUB.FNNONS': 'Gastos Logística',\n",
    "                 'UIS.XGDP.FSGOV.FDINSTADM.FFD': 'Gastos Infraestrutura', \n",
    "                 'SE.XPD.TOTL.GD.ZS': 'Gastos Governo'}\n",
    "\n",
    "df_analfabetismo_15_a_24 = df_analfabetismo_15_a_24.rename(columns = nomes_colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforma os indicadores, dos mesmos países selecionados acima, em colunas. Isso é feito para o período entre 2012 e 2013 (dados de teste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analfabetismo_15_a_24_teste = pd.DataFrame()\n",
    "\n",
    "for indicador in indicadores_15_a_24:\n",
    "    df_indicador_teste = df_resultado_transformacao_teste.loc[df_resultado_transformacao_teste['Indicador'] == indicador]\n",
    "    df_indicador_teste = df_indicador_teste.loc[df_indicador_teste['Pais'].isin(df_paises_na_media['Pais'])]\n",
    "    df_indicador_teste.index = range(df_indicador_teste.shape[0])\n",
    "    \n",
    "    df_periodos_indicador_teste = df_indicador_teste.drop(['Pais', 'Indicador'], axis=1)    \n",
    "    df_periodos_indicador_teste = df_periodos_indicador_teste.stack()\n",
    "    df_periodos_indicador_teste.index = range(df_periodos_indicador_teste.shape[0])\n",
    "    df_analfabetismo_15_a_24_teste[indicador] = df_periodos_indicador_teste.tolist()\n",
    "\n",
    "df_analfabetismo_15_a_24_teste = df_analfabetismo_15_a_24_teste.rename(columns = nomes_colunas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise e previsão dos dados para a taxa de analfabetismo de 15 a 24 anos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.Introdução à classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinaremos com 3038 elementos e testaremos com 217 elementos\n",
      "Taxa de acerto: 91.24\n",
      "A acurácia do algoritmo de baseline foi de 91.24%\n"
     ]
    }
   ],
   "source": [
    "# Realiza a previsão separando os dados entre treinamento (todos os dados do período de 1998 a 2012) \n",
    "# e testes (todos os dados do período de 2012 a 2013).\n",
    "\n",
    "#1998 a 2012\n",
    "treino_x = df_analfabetismo_15_a_24.loc[:, ['Gastos Pessoas', 'Gastos Totais', 'Gastos Logística', 'Gastos Infraestrutura', 'Gastos Governo']]\n",
    "treino_y = df_analfabetismo_15_a_24.loc[:, 'Analfabetismo 15 a 24']\n",
    "\n",
    "#2012 a 2013\n",
    "teste_x = df_analfabetismo_15_a_24_teste.loc[:, ['Gastos Pessoas', 'Gastos Totais', 'Gastos Logística', 'Gastos Infraestrutura', 'Gastos Governo']]\n",
    "teste_y = df_analfabetismo_15_a_24_teste.loc[:, 'Analfabetismo 15 a 24']\n",
    "\n",
    "modelo = LinearSVC()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "previsoes = modelo.predict(teste_x)\n",
    "taxa_de_acerto = accuracy_score(teste_y, previsoes)\n",
    "\n",
    "print(\"Treinaremos com %d elementos e testaremos com %d elementos\" % (len(treino_x), len(teste_x)))\n",
    "print(\"Taxa de acerto: %.2f\" % (taxa_de_acerto * 100))\n",
    "\n",
    "#Geração da baseline para verificar se a acurácia foi boa ou ruim.\n",
    "previsoes_baseline = np.zeros(217)\n",
    "acuracia = accuracy_score(teste_y, previsoes_baseline)\n",
    "print(\"A acurácia do algoritmo de baseline foi de %.2f%%\" % (acuracia * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Testes replicáveis, estratificação e lendo dados da internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinaremos com 2441 elementos e testaremos com 814 elementos\n",
      "A acurácia foi de 89.19%\n"
     ]
    }
   ],
   "source": [
    "# A diferença entre esse cenário ao anterior, é que aqui a divisão da massa de testes é o número de registros.\n",
    "# Ou seja, aqui foi utilizado 75% de todos os registros (101 elementos do período de 1998 a 2013) para \n",
    "# treinamento e 25% (34 elementos do período de 1998 a 2013) para testes.\n",
    "\n",
    "#1998 a 2013\n",
    "df_analfabetismo_15_a_24_total = df_analfabetismo_15_a_24.append(df_analfabetismo_15_a_24_teste)\n",
    "x = df_analfabetismo_15_a_24_total[['Gastos Pessoas', 'Gastos Totais', 'Gastos Logística', 'Gastos Infraestrutura', 'Gastos Governo']]\n",
    "y = df_analfabetismo_15_a_24_total['Analfabetismo 15 a 24']\n",
    "\n",
    "treino_x = x[:2441]\n",
    "treino_y = y[:2441]\n",
    "teste_x = x[2441:]\n",
    "teste_y = y[2441:]\n",
    "print(\"Treinaremos com %d elementos e testaremos com %d elementos\" % (len(treino_x), len(teste_x)))\n",
    "\n",
    "modelo = LinearSVC()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "previsoes = modelo.predict(teste_x)\n",
    "acuracia = accuracy_score(teste_y, previsoes)\n",
    "print(\"A acurácia foi de %.2f%%\" % (acuracia * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinaremos com 2441 elementos e testaremos com 814 elementos\n",
      "A acurácia foi de 88.94%\n",
      "A acurácia do algoritmo de baseline foi de 88.94%\n"
     ]
    }
   ],
   "source": [
    "# Divisão automática da massa de treinamento e testes. Isso foi feito através do \"train_test_split\" da lib \"SKLearn\"\n",
    "\n",
    "#Define a ordem dos números aleatórios.\n",
    "#Assim, tetira a aleatoriedade da separação dos dados de treino e teste.\n",
    "SEED = 5\n",
    "np.random.seed(SEED)\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, random_state = SEED, test_size=0.25, stratify=y)\n",
    "#O parâmetro \"stratify=y\" orienta o algoritmo a estratificar (separar proporcionalmente) os dados de acordo com o \"y\".\n",
    "\n",
    "print(\"Treinaremos com %d elementos e testaremos com %d elementos\" % (len(treino_x), len(teste_x)))\n",
    "\n",
    "modelo = LinearSVC()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "previsoes = modelo.predict(teste_x)\n",
    "acuracia = accuracy_score(teste_y, previsoes)\n",
    "print(\"A acurácia foi de %.2f%%\" % (acuracia * 100))\n",
    "\n",
    "#Geração da baseline para verificar se a acurácia foi boa ou ruim.\n",
    "previsoes_baseline = np.zeros(814)\n",
    "acuracia = accuracy_score(teste_y, previsoes_baseline)\n",
    "print(\"A acurácia do algoritmo de baseline foi de %.2f%%\" % (acuracia * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinaremos com 2441 elementos e testaremos com 814 elementos\n",
      "A acurácia foi de 88.94%\n",
      "A acurácia do algoritmo de baseline foi de 88.94%\n"
     ]
    }
   ],
   "source": [
    "# Utilização do modelo \"SVC\"\n",
    "\n",
    "#Define a ordem dos números aleatórios.\n",
    "#Assim, tetira a aleatoriedade da separação dos dados de treino e teste.\n",
    "SEED = 5\n",
    "np.random.seed(SEED)\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, random_state = SEED, test_size=0.25, stratify=y)\n",
    "#O parâmetro \"stratify=y\" orienta o algoritmo a estratificar (separar proporcionalmente) os dados de acordo com o \"y\".\n",
    "\n",
    "print(\"Treinaremos com %d elementos e testaremos com %d elementos\" % (len(treino_x), len(teste_x)))\n",
    "\n",
    "#Reescalando os dados para uma faixa similar.\n",
    "\n",
    "\n",
    "modelo = SVC()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "previsoes = modelo.predict(teste_x)\n",
    "acuracia = accuracy_score(teste_y, previsoes)\n",
    "print(\"A acurácia foi de %.2f%%\" % (acuracia * 100))\n",
    "\n",
    "#Geração da baseline para verificar se a acurácia foi boa ou ruim.\n",
    "previsoes_baseline = np.zeros(814)\n",
    "acuracia = accuracy_score(teste_y, previsoes_baseline)\n",
    "print(\"A acurácia do algoritmo de baseline foi de %.2f%%\" % (acuracia * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3) Transformação e seleção para o indicador de analfabetismo entre 25 a 64 anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicadores_25_a_64 = ['UIS.ILLPOP.AG25T64', 'UIS.XSPENDP.FDPUB.FNS', 'UIS.XSPENDP.FDPUB.FNCAP', \n",
    "                       'UIS.XSPENDP.FDPUB.FNNONS', 'UIS.XGDP.FSGOV.FDINSTADM.FFD', 'SE.XPD.TOTL.GD.ZS']\n",
    "\n",
    "df_analfabetismo_25_a_64 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.4) Transformação e seleção para o indicador de analfabetismo para 65 anos ou mais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicadores_65 = ['UIS.LP.AG65', 'UIS.XSPENDP.FDPUB.FNS', 'UIS.XSPENDP.FDPUB.FNCAP', \n",
    "                  'UIS.XSPENDP.FDPUB.FNNONS', 'UIS.XGDP.FSGOV.FDINSTADM.FFD', 'SE.XPD.TOTL.GD.ZS']\n",
    "\n",
    "df_analfabetismo_65 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.5) Validação da eficiência da previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinaremos com 2441 elementos e testaremos com 814 elementos\n",
      "A acurácia foi 88.94%\n"
     ]
    }
   ],
   "source": [
    "#6) Aplicar algoritmo de classificação e previsão\n",
    "\n",
    "\n",
    "#Fatos:\n",
    "#1) As linhas do dataframe estão agrupadas por países.\n",
    "#2) Cada país possui uma lista de indicadores.\n",
    "#3) A lista de indicadores é dividida em dois grupos:\n",
    "#   Grupo 1 = indicadores de analfabetismo (influenciados): UIS.LP.AG15T24, UIS.ILLPOP.AG25T64, UIS.LP.AG65\n",
    "#   Grupo 2 = indicadores econômicos (influenciadores): UIS.XSPENDP.FDPUB.FNS, UIS.XSPENDP.FDPUB.FNCAP, UIS.XSPENDP.FDPUB.FNNONS, UIS.XGDP.FSGOV.FDINSTADM.FFD, SE.XPD.TOTL.GD.ZS\n",
    "#4) Além disso, existem as colunas (com e 1) da diferença entre os anos de 1998 a 2013.\n",
    "\n",
    "#O quê fazer?\n",
    "#1) Transformar o dataset em:\n",
    "#   Linhas = período de anos (1998-1999, 1999-2000, ..., 2012-2013)\n",
    "#   Colunas = um indicador por coluna: UIS.LP.AG15T24, UIS.ILLPOP.AG25T64, UIS.LP.AG65, UIS.XSPENDP.FDPUB.FNS, UIS.XSPENDP.FDPUB.FNCAP, UIS.XSPENDP.FDPUB.FNNONS, UIS.XGDP.FSGOV.FDINSTADM.FFD, SE.XPD.TOTL.GD.ZS\n",
    "\n",
    "\n",
    "df_periodo_datas = df_resultado_transformacao.iloc[:, 2:18]\n",
    "\n",
    "\n",
    "SEED = 20\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(x, y,\n",
    "                                                         random_state = SEED, test_size = 0.25,\n",
    "                                                         stratify = y)\n",
    "print(\"Treinaremos com %d elementos e testaremos com %d elementos\" % (len(treino_x), len(teste_x)))\n",
    "\n",
    "modelo = LinearSVC()\n",
    "modelo.fit(treino_x, treino_y)\n",
    "previsoes = modelo.predict(teste_x)\n",
    "\n",
    "acuracia = accuracy_score(teste_y, previsoes) * 100\n",
    "print(\"A acurácia foi %.2f%%\" % acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.6) Carga e transformação da massa bruta dos dados com pelo menos 50% dos valores preenchidos.\n",
    "\n",
    "Isso reduzirá a quantidade de elementos para 351. Na solução 3.1.1, sem a restrição de 50% do preenchimento, foram utilizados 1953 elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2f7c1ddf6ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdf_1998_a_2013\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_1998_a_2013\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ffill'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bfill'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindicador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mvalor_1998_1999\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf_1998_a_2013\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1999'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_1998_a_2013\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1998'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mvalor_1999_2000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf_1998_a_2013\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2000'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_1998_a_2013\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1999'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "massa_bruta_pais_por_indicadores = pd.read_csv('../data/massa_bruta_pais_por_indicadores.csv')\n",
    "\n",
    "paises = massa_bruta_pais_por_indicadores['Country Name'].unique()\n",
    "\n",
    "df_massa_bruta_por_indicador = massa_bruta_pais_por_indicadores.loc[massa_bruta_pais_por_indicadores['Indicator Code'].isin(indicadores)]\n",
    "\n",
    "df_classificado = pd.DataFrame(columns=colunas_transformacao)\n",
    "\n",
    "for pais in paises:\n",
    "    df_pais = df_massa_bruta_por_indicador.loc[df_massa_bruta_por_indicador['Country Name'] == pais]\n",
    "\n",
    "    df_1998_a_2013 = df_pais.iloc[:, 2:18]\n",
    "    df_1998_a_2013.index = range(df_1998_a_2013.shape[0])\n",
    "    media_valores_invalidos = df_1998_a_2013.isna().mean(axis=1).mean()\n",
    "    \n",
    "    if media_valores_invalidos < 0.5:\n",
    "        \n",
    "        df_1998_a_2013 = df_1998_a_2013.fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).fillna(0)\n",
    "        \n",
    "        for index, value in indicador.items():            \n",
    "            valor_1998_1999 = 1 if df_1998_a_2013['1999'].iloc[0] - df_1998_a_2013['1998'].iloc[0] > 0 else 0\n",
    "            valor_1999_2000 = 1 if df_1998_a_2013['2000'].iloc[0] - df_1998_a_2013['1999'].iloc[0] > 0 else 0\n",
    "            valor_2000_2001 = 1 if df_1998_a_2013['2001'].iloc[0] - df_1998_a_2013['2000'].iloc[0] > 0 else 0\n",
    "            valor_2001_2002 = 1 if df_1998_a_2013['2002'].iloc[0] - df_1998_a_2013['2001'].iloc[0] > 0 else 0\n",
    "            valor_2002_2003 = 1 if df_1998_a_2013['2003'].iloc[0] - df_1998_a_2013['2002'].iloc[0] > 0 else 0\n",
    "            valor_2003_2004 = 1 if df_1998_a_2013['2004'].iloc[0] - df_1998_a_2013['2003'].iloc[0] > 0 else 0\n",
    "            valor_2004_2005 = 1 if df_1998_a_2013['2005'].iloc[0] - df_1998_a_2013['2004'].iloc[0] > 0 else 0\n",
    "            valor_2005_2006 = 1 if df_1998_a_2013['2006'].iloc[0] - df_1998_a_2013['2005'].iloc[0] > 0 else 0\n",
    "            valor_2006_2007 = 1 if df_1998_a_2013['2007'].iloc[0] - df_1998_a_2013['2006'].iloc[0] > 0 else 0\n",
    "            valor_2007_2008 = 1 if df_1998_a_2013['2008'].iloc[0] - df_1998_a_2013['2007'].iloc[0] > 0 else 0\n",
    "            valor_2008_2009 = 1 if df_1998_a_2013['2009'].iloc[0] - df_1998_a_2013['2008'].iloc[0] > 0 else 0\n",
    "            valor_2009_2010 = 1 if df_1998_a_2013['2010'].iloc[0] - df_1998_a_2013['2009'].iloc[0] > 0 else 0\n",
    "            valor_2010_2011 = 1 if df_1998_a_2013['2011'].iloc[0] - df_1998_a_2013['2010'].iloc[0] > 0 else 0\n",
    "            valor_2011_2012 = 1 if df_1998_a_2013['2012'].iloc[0] - df_1998_a_2013['2011'].iloc[0] > 0 else 0\n",
    "            valor_2012_2013 = 1 if df_1998_a_2013['2013'].iloc[0] - df_1998_a_2013['2012'].iloc[0] > 0 else 0\n",
    "            \n",
    "            valores = [pais, value, valor_1998_1999, valor_1999_2000, valor_2000_2001, valor_2001_2002, \n",
    "                       valor_2002_2003, valor_2003_2004, valor_2004_2005, valor_2005_2006, valor_2006_2007, \n",
    "                       valor_2007_2008, valor_2008_2009, valor_2009_2010, valor_2010_2011, valor_2011_2012, \n",
    "                       valor_2012_2013]\n",
    "\n",
    "            df_auxiliar = pd.DataFrame([valores], columns=colunas_transformacao)\n",
    "            df_auxiliar.index = range(df_auxiliar.shape[0])\n",
    "            df_classificado = pd.concat([df_auxiliar, df_classificado])\n",
    "        \n",
    "df_classificado = df_classificado.sort_values(['Pais'], ascending=[True])\n",
    "df_classificado.index = range(df_classificado.shape[0])\n",
    "df_classificado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2.1) Validação da eficiência da previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classificado.describe().round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
